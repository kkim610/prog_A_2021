{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Computer vision is a field of artificial intelligence that trains computers to interpret and understand the visual world from digital images or videos. From the perspective of engineering, it seeks to understand and automate tasks that the human visual system can do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## How does a computer read an image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "How does a human mind apprehend an image? When you see the image below,what do you actually see and how do you say what is in the Image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/lincoln_pixel_values.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You  most probably look for different shapes and colours in the Image and that might help you decide that this is an image of Lincoln. But does a computer also see it in the same way? The answer is no."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "A digital image is an image composed of picture elements, also known as pixels, each with finite, discrete quantities of numeric representation for its intensity or grey level. So the computer sees an image as numerical values of these pixels and in order to recognise a certain image, it has to recognise the patterns and regularities in this numerical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## What is OpenCV?\n",
    "OpenCV ( Open Source Computer Vision Library) is an open source software library for computer vision and machine learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Gary Bradsky invented OpenCV in 1999 and soon the first release came in 2000. This library is based on optimised C / C++ and supports Java and Python along with C++ through an interface. The library has more than 2500 optimised algorithms, including an extensive collection of computer vision and machine learning algorithms, both classic and state-of-the-art.Using OpenCV it becomes easy to do complex tasks such as identify and recognise faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D object models, generate 3D point clouds from stereo cameras, stitch images together to generate an entire scene with a high resolution image and many more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Image 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "사전적 정의:   \n",
    "(Wikipedia 한글요약) image는 사진이나 이차원 그림처럼 시지각(시각적 인식)을 묘사하는 (피사체를 닮은)인공물 \n",
    "\n",
    "Wikipedia:  \n",
    "An image (from Latin: imago) is an artifact that depicts visual perception, such as a photograph or other two-dimensional picture, particularly one that resembles a subject (usually a physical object). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "이미지 처리 분야에서의 정의:  \n",
    "**image 란  2차원(혹은 3차원) 공간에서 color intensity를 갖는 점(픽셀)들의 집합**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "수학적 정의:  \n",
    "An image is defined as a two-dimensional function,F(x,y), where x and y are spatial coordinates(공간좌표), and the amplitude of F at any pair of coordinates (x,y) is called the intensity of that image at that point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "이미지를 구성하는 x,y,F(x,y) 가 digital 값을 가질 때, digital image 라 한다. \n",
    "여기에서 F(x,y)는 이차원 이미지의 (x,y) 좌표에서의 color intensity를 의미한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**픽셀(pixel)**: Picture Element의 준말. 화소(畵素)라고도 한다. 이 점 하나에 해당 색의 정보(빨간색, 녹색, 파란색, 투명도 등)가 담겨져 있으며, 이는 곧 그림의 용량과 직결된다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**Gray Level**: 각 픽셀이 갖는 영상의 밝기를 나타내는 값. 보통 0에서 255 사이의 값을 갖는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_6.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**resolution(해상도)**: The term resolution is often considered equivalent to pixel count in digital imaging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The above image  has a resolution of 1,000×750, meaning that it is 1,000 pixels\n",
    "wide and 750 pixels tall. We can conceptualize an image as a (multidimensional) matrix. In this\n",
    "case, our matrix has 1,000 columns (the width) with 750 rows (the height). Overall, there are\n",
    "1,000×750 = 750,000 total pixels in our image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_7.jpg\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Image의 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Binary Image:   \n",
    "A binary image has only two possible gray values or intensities 0 (검정색) and 255 (흰색),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_1.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Grayscale Image (Black and White Image): \n",
    "Each pixel in grayscale image can have any value between 0 and 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_2.jpeg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_4.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Color Image: \n",
    "Both binary image and grayscale image are 2-dimensional arrays, where at every location, you have one value to represent the pixel.   \n",
    "Typically you need 3 values for each pixel to represent any color.   \n",
    "This came from the idea that any color can be formed by combining 3 basic colors Blue, Green and Red (BGR). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_3.jpeg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### image as a matrix (or array in python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np  # numpy: numrical python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## How to install opencv for python on Windows 10\n",
    "### anaconda prompt 에서 다음을 입력하고 리턴 키를 누른다.\n",
    "### pip install opencv-python¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m=np.arange(0,11)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m=np.arange(0,256, dtype=\"uint8\")\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "m2=np.tile(m,(256,1))\n",
    "print(m2.shape)\n",
    "m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('m2', m2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### image to matrix in grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fname = 'pic/fig_0_2.jpeg' #puppy\n",
    "\n",
    "#original = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "gray = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "#cv2.imshow('Original', original)\n",
    "cv2.imshow('Gray', gray)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "type(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray2=gray.copy()\n",
    "gray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray2[0:100,0:150]=0\n",
    "gray2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Gray2', gray2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray3=gray.copy()\n",
    "gray3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray3[160:230,140:230]=255\n",
    "gray3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Gray3', gray3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Gray', gray)\n",
    "cv2.imshow('Gray2', gray2)\n",
    "cv2.imshow('Gray3', gray3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Color pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Pixels in the RGB color space are no longer a scalar value like in a grayscale/single channel\n",
    "image – instead, the pixels are represented by a list of three values: one value for the Red component,\n",
    "one for Green, and another for Blue.    \n",
    "To define a color in the RGB color model, all we need to do is\n",
    "define the amount of Red, Green, and Blue contained in a single pixel.  \n",
    "Each Red, Green, and Blue channel can have values defined in the range [0,255] for a total of\n",
    "256 “shades”, where 0 indicates no representation and 255 demonstrates full representation.   \n",
    "Given\n",
    "that the pixel value only needs to be in the range [0,255], we normally use 8-bit unsigned integers\n",
    "to represent the intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_5.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Given our three Red, Green, and Blue values, we can combine them into an RGB tuple in the\n",
    "form (red, green, blue).   \n",
    "This tuple represents a given color in the RGB color space.   \n",
    "The\n",
    "RGB color space is an example of an additive color space: the more of each color is added, the\n",
    "brighter the pixel becomes and closer to white."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_08.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_09.jpg\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "연습: https://www.w3schools.com/colors/colors_rgb.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fname = 'pic/fig_0_3.jpeg' \n",
    "\n",
    "#original = cv2.imread(fname, cv2.IMREAD_COLOR)\n",
    "bird = cv2.imread(fname)\n",
    "cv2.imshow('Bird', bird)\n",
    "\n",
    "gray_bird = cv2.imread(fname, cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow('Gray_Bird', gray_bird)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gray_bird.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### opencv: The order of color is BGR (blue, green, red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird[:,:,0] # blue channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird[:,:,1] # green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird[:,:,2] # red channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "b = bird.copy()\n",
    "\n",
    "# set green and red channels to 0\n",
    "b[:, :, 1] = 0\n",
    "b[:, :, 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Blue_Bird',b)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "g = bird.copy()\n",
    "\n",
    "# set green and red channels to 0\n",
    "g[:, :, 0] = 0\n",
    "g[:, :, 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Green_Bird',g)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "r = bird.copy()\n",
    "\n",
    "# set green and red channels to 0\n",
    "r[:, :, 0] = 0\n",
    "r[:, :, 1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Red_Bird',r)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Bird',bird)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_10.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### BGR vs RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "bird_plt = plt.imread(fname)\n",
    "\n",
    "plt.imshow(bird_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "bird_cv2 = cv2.imread(fname)\n",
    "\n",
    "cv2.imshow('Bird',bird_cv2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "cv2에서 읽어들인 이미지를 plt에서 인쇄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "plt.imshow(bird_cv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "plt에서 읽어들인 이미지를 cv2에서 인쇄 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "cv2.imshow('Bird',bird_plt)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird_cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(bird_plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,0] #blue channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_plt[:,:,0] #red channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,1] #green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_plt[:,:,1] #green channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,2] #red channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_plt[:,:,2] #blue channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,0]==bird_plt[:,:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,1]==bird_plt[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,2]==bird_plt[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,2]==bird_plt[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "bird_cv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sum(bird_cv2[:,:,0]==bird_plt[:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sum(bird_cv2[:,:,2]==bird_plt[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bird_cv2[:,:,2]-bird_plt[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "np.sum(bird_cv2[:,:,2]-bird_plt[:,:,0])/(700*1120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## cv2 --> BGR    \n",
    "## plt   --> RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## image standard: RGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "그러나, cv2.imread()로 읽어서 cv2.imshow()로 인쇄할 때는 신경쓸 필요없다. 즉 cv2 내에서는 컬러 순서를 잊어도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "다만, cv2와 다른 패키지를 섞어 사용할 때는 조심해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "그러면, cv2.imread()로 읽은 이미지를 plt.imshow()로 인쇄하려면?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "cv2.imread()로 읽은 이지지는 BGR 순서이고, plt.imshow()는 RGB 순서인 이미지를 인쇄하므로, BGR을 RGB로 바꾸면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "img_corrected = cv2.cvtColor(bird_cv2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "비슷한 방법으로 plt.imread()로 읽은 이미지를 cv2.imshow()로 인쇄하는 방법은 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "img_corrected_2 = cv2.cvtColor(bird_plt, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "cv2.imshow('img_corrected_2',img_corrected_2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Scaling (크기조정) and Aspect Ratios (화면비율, 가로세로비율)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Scaling, or simply resizing, is the process of increasing or decreasing the size of an image in terms\n",
    "of width and height.   \n",
    "When resizing an image, it’s important to keep in mind the aspect ratio, which is the ratio of the width to the height of the image. Ignoring the aspect ratio can lead to images that\n",
    "look compressed and distorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Scaling은 이미지의 사이즈가 변하는 것 입니다.   \n",
    "OpenCV에서는 cv2.resize() 함수를 사용하여 적용할 수 있습니다.   \n",
    "사이즈가 변하면 pixel사이의 값을 결정을 해야 하는데, 이때 사용하는 것을 보간법(Interpolation method)입니다.   \n",
    "많이 사용되는 보간법은 사이즈를 줄일 때는 cv2.INTER_AREA , 사이즈를 크게할 때는 cv2.INTER_CUBIC , cv2.INTER_LINEAR 을 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_0_11.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "img = cv2.imread('pic/messi5.jpg')\n",
    "\n",
    "# 행 : Height, 열:width\n",
    "height, width = img.shape[:2]\n",
    "\n",
    "# 이미지 축소\n",
    "shrink = cv2.resize(img, None, fx=0.5, fy=0.5, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Manual Size지정\n",
    "zoom1 = cv2.resize(img, (width*2, height*2), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "# 배수 Size지정\n",
    "zoom2 = cv2.resize(img, None, fx=2, fy=2, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "\n",
    "cv2.imshow('Origianl', img)\n",
    "cv2.imshow('Shrink', shrink)\n",
    "cv2.imshow('Zoom1', zoom1)\n",
    "cv2.imshow('Zoom2', zoom2)\n",
    "\n",
    "print(img.shape)\n",
    "print(shrink.shape)\n",
    "print(zoom1.shape)\n",
    "print(zoom2.shape)\n",
    "\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
