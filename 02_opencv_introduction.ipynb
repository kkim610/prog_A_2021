{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 11. Bitwise Operations (bitwise AND, OR, NOT and XOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = np.zeros((250, 500, 3), np.uint8)\n",
    "img1 = cv2.rectangle(img1,(250, 0), (500, 250), (255, 255, 255), -1)\n",
    "cv2.imwrite(\"image_1.png\", img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"image_1.png\")\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"image_1.png\")\n",
    "img2 = np.zeros((250, 500, 3), np.uint8)\n",
    "img2 = cv2.rectangle(img2,(200, 0), (300, 100), (255, 255, 255), -1)\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### bitwise_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"image_1.png\")\n",
    "img2 = np.zeros((250, 500, 3), np.uint8)\n",
    "img2 = cv2.rectangle(img2,(200, 0), (300, 100), (255, 255, 255), -1)\n",
    "\n",
    "bitAnd = cv2.bitwise_and(img1, img2)\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow('bitAnd', bitAnd)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/bitwise_and1.jpg\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br><br><img style=\"float: left;\" src=\"pic/bitwise_and2.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### bitwise_or"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"image_1.png\")\n",
    "img2 = np.zeros((250, 500, 3), np.uint8)\n",
    "img2 = cv2.rectangle(img2,(200, 0), (300, 100), (255, 255, 255), -1)\n",
    "\n",
    "bitOr = cv2.bitwise_or(img1, img2)\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow('bitOr', bitOr)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/bitwise_or1.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<br><br><br><img style=\"float: left;\" src=\"pic/bitwise_or2.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img1 = cv2.imread(\"image_1.png\")\n",
    "img2 = np.zeros((250, 500, 3), np.uint8)\n",
    "img2 = cv2.rectangle(img2,(200, 0), (300, 100), (255, 255, 255), -1)\n",
    "\n",
    "bitAnd = cv2.bitwise_and(img1, img2)\n",
    "bitOr = cv2.bitwise_or(img1, img2)\n",
    "bitXor = cv2.bitwise_xor(img1, img2)\n",
    "bitNot1 = cv2.bitwise_not(img1)\n",
    "bitNot2 = cv2.bitwise_not(img2)\n",
    "\n",
    "cv2.imshow(\"img1\", img1)\n",
    "cv2.imshow(\"img2\", img2)\n",
    "cv2.imshow('bitAnd', bitAnd)\n",
    "cv2.imshow('bitOr', bitOr)\n",
    "cv2.imshow('bitXor', bitXor)\n",
    "cv2.imshow('bitNot1', bitNot1)\n",
    "cv2.imshow('bitNot2', bitNot2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 12. How to Bind Trackbar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27: # Esc 키\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image2')   # 새로운 윈도우창 생성  # trackbar를 위한 창\n",
    "\n",
    "cv2.createTrackbar('B', 'image2', 0, 255, nothing)\n",
    "cv2.createTrackbar('G', 'image2', 0, 255, nothing)\n",
    "cv2.createTrackbar('R', 'image2', 0, 255, nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "\n",
    "cv2.namedWindow('image2')\n",
    "cv2.createTrackbar('B', 'image2', 0, 255, nothing)\n",
    "cv2.createTrackbar('G', 'image2', 0, 255, nothing)\n",
    "cv2.createTrackbar('R', 'image2', 0, 255, nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    b = cv2.getTrackbarPos('B', 'image2')\n",
    "    g = cv2.getTrackbarPos('G', 'image2')\n",
    "    r = cv2.getTrackbarPos('R', 'image2')\n",
    "\n",
    "    img[:] = [b, g, r]\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image') # trackbar의 결과를 같은 창에 나타내기위해 image 라는 동일한 이름 사용\n",
    "\n",
    "cv2.createTrackbar('B', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('G', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('R', 'image', 0, 255, nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    b = cv2.getTrackbarPos('B', 'image')\n",
    "    g = cv2.getTrackbarPos('G', 'image')\n",
    "    r = cv2.getTrackbarPos('R', 'image')\n",
    "\n",
    "    img[:] = [b, g, r]\n",
    "\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 \n",
    "\n",
    "def nothing(x):\n",
    "    print(x)\n",
    "\n",
    "# Create a black image, a window\n",
    "img = np.zeros((300,512,3), np.uint8)\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "cv2.createTrackbar('B', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('G', 'image', 0, 255, nothing)\n",
    "cv2.createTrackbar('R', 'image', 0, 255, nothing)\n",
    "\n",
    "switch = '0 : OFF\\n 1 : ON'\n",
    "cv2.createTrackbar(switch, 'image', 0, 1, nothing)\n",
    "\n",
    "while(1):\n",
    "    cv2.imshow('image',img)\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "    b = cv2.getTrackbarPos('B', 'image')\n",
    "    g = cv2.getTrackbarPos('G', 'image')\n",
    "    r = cv2.getTrackbarPos('R', 'image')\n",
    "    s = cv2.getTrackbarPos(switch, 'image')\n",
    "\n",
    "    if s == 0:\n",
    "        img[:] = 0\n",
    "    else:\n",
    "        img[:] = [b, g, r]\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 13. Object Detection and Object Tracking Using HSV Color Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "**HSV(Hue,Saturation, Value)**  \n",
    "색상(Hue), 채도(Saturation), 명도(Value)\n",
    "* Hue corresponds to the color components (base pigment), hense just by selecting a range of Hue you can select any color. (0-179)\n",
    "* Saturation is the amount of color (depth of the pigment) (dominance of Hue) (0 - 255)\n",
    "* Value is basically the brightness of the color (0-255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_04.png\" width=\"350\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "다음 그림에서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread('pic/smarties.png')\n",
    "\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "파란 색만 catch 해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#def nothing(x):\n",
    "#    pass\n",
    "\n",
    "#cv2.namedWindow(\"Tracking\")\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread('pic/smarties.png')\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_b = np.array([110, 50, 50])\n",
    "    u_b = np.array([130, 255, 255])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "되기는 하는데, 정밀하지 못하다.  \n",
    "Trackbar를 이용하여 보다 정밀하게 찾아보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 360, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 179, 179, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    frame = cv2.imread('pic/smarties.png')\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "\n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    #cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "79-113-188-154-255-255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Video 에서 object tracking을 해 보자.  \n",
    "연한 하늘색의 경우: LH82, LS51, LV51, UH133, US255,UV255 로 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cv2.namedWindow(\"Tracking\")\n",
    "cv2.createTrackbar(\"LH\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LS\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"LV\", \"Tracking\", 0, 255, nothing)\n",
    "cv2.createTrackbar(\"UH\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"US\", \"Tracking\", 255, 255, nothing)\n",
    "cv2.createTrackbar(\"UV\", \"Tracking\", 255, 255, nothing)\n",
    "\n",
    "while True:\n",
    "    #frame = cv2.imread('smarties.png')\n",
    "    _,frame = cap.read()\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    l_h = cv2.getTrackbarPos(\"LH\", \"Tracking\")\n",
    "    l_s = cv2.getTrackbarPos(\"LS\", \"Tracking\")\n",
    "    l_v = cv2.getTrackbarPos(\"LV\", \"Tracking\")\n",
    "\n",
    "    u_h = cv2.getTrackbarPos(\"UH\", \"Tracking\")\n",
    "    u_s = cv2.getTrackbarPos(\"US\", \"Tracking\")\n",
    "    u_v = cv2.getTrackbarPos(\"UV\", \"Tracking\")\n",
    "\n",
    "    l_b = np.array([l_h, l_s, l_v])\n",
    "    u_b = np.array([u_h, u_s, u_v])\n",
    "\n",
    "    mask = cv2.inRange(hsv, l_b, u_b)\n",
    "\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "    cv2.imshow(\"mask\", mask)\n",
    "    cv2.imshow(\"res\", res)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 14. Simple Image Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "thresholding: 배경과 물체를 구분할 때 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Thresholding transforms images into binary images. We need to set the threshold value and max values and then we convert the pixel values accordingly. There are five different types of thresholding: Binary, the inverse of Binary, Threshold to zero, the inverse of Threshold to Zero, and Threshold truncation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_2_14.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "thresholding type은 아래와 같습니다.  \n",
    "cv2.THRESH_BINARY: 픽셀값이 threshold value 보다 크면 maxval 적용, 이하이면 0 적용   \n",
    "cv2.THRESH_BINARY_INV: 픽셀값이 threshold value 보다 크면 0 적용, 이하이면 maxvalue 적용  \n",
    "cv2.THRESH_TRUNC: 픽셀값이 threshold value 보다 크면 threshold value 적용, 이하이면 그대로  \n",
    "cv2.THRESH_TOZERO: 픽셀값이 threshold value 보다 크면 그대로, 이하이면 0 적용   \n",
    "cv2.THRESH_TOZERO_INV: 픽셀값이 threshold value 보다 크면 0, 이하이면 그대로  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('pic/gradient.png',0)\n",
    "_, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"th1\", th1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('pic/gradient.png',0)\n",
    "_, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "_, th2 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"th1\", th1)\n",
    "cv2.imshow(\"th2\", th2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('pic/gradient.png',0)\n",
    "_, th1 = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY)\n",
    "_, th2 = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "_, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)  # 127까지는 원본대로, 127보다 크면 127번 값을 갖는다.\n",
    "_, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO) # 127 까지는 0, 127보다 크면 원본대로\n",
    "_, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"th1\", th1)\n",
    "cv2.imshow(\"th2\", th2)\n",
    "cv2.imshow(\"th3\", th3)\n",
    "cv2.imshow(\"th4\", th4)\n",
    "cv2.imshow(\"th5\", th5)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/threshold.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 15. Adaptive Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "임계값을 이미지 전체에 적용하여 처리하기 때문에 하나의 이미지에 음영이 다르면 일부 영역이 모두 흰색 또는 검정색으로 보여지게 됩니다.\n",
    "\n",
    "lighting condition 이 image 내에서도 서로 다르기 때문에 adaptive 하게 조정할 필요\n",
    "\n",
    "이런 문제를 해결하기 위해서 이미지의 작은 영역별로 thresholding을 하는 것입니다. 이때 사용하는 함수가 cv2.adaptiveThreshold() 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "By calculating the threshold within the neighborhood area of the image, we can achieve a better result from images with varying illumination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "cv2.adaptiveThreshold(src, maxValue, adaptiveMethod, thresholdType, blockSize, C)\n",
    "\n",
    "Parameters:  \n",
    "src: grayscale image  \n",
    "maxValue: 조건이 만족 되었을 때 픽셀에 적용하는 값  \n",
    "adaptiveMethod: thresholding value를 결정하는 계산 방법  (ADAPTIVE_THRESH_MEAN_C  or DAPTIVE_THRESH_GAUSSIAN_C) \n",
    "thresholdType:THRESH_BINARY or THRESH_BINARY_INV  \n",
    "blockSize – thresholding을 적용할 영역 사이즈, 반드시 홀수 일것. \n",
    "C: 평균이나 가중평균에서 차감할 값  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('pic/sudoku.png',0)\n",
    "_, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"THRESH_BINARY\", th1)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('pic/sudoku.png',0)\n",
    "_, th1 = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY)\n",
    "th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2);\n",
    "th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2);\n",
    "\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.imshow(\"THRESH_BINARY\", th1)\n",
    "cv2.imshow(\"ADAPTIVE_THRESH_MEAN_C\", th2)\n",
    "cv2.imshow(\"ADAPTIVE_THRESH_GAUSSIAN_C\", th3)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 16. matplotlib with OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/lena.jpg', -1)\n",
    "cv2.imshow('image', img)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "결과에 차이가 나는 이유  \n",
    "cv2: BGR 사용  \n",
    "matplotlib: RGB 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/lena.jpg', -1)\n",
    "cv2.imshow('image', img)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.xticks([]), plt.yticks([])\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "앞에서의 threshold 결과를 한번에 나타내보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/gradient.png',0)\n",
    "_, th1 = cv2.threshold(img, 50, 255, cv2.THRESH_BINARY)\n",
    "_, th2 = cv2.threshold(img, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "_, th3 = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC)  # 127까지는 원본대로, 127이상은 127번 값을 갖는다.\n",
    "_, th4 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO) # 127 까지는 0, 127보다 크면 원본대로\n",
    "_, th5 = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "\n",
    "titles = ['Original Image','Binary', 'Binary_Inv', 'Trunc', 'ToZero','ToZero_Inv']\n",
    "images = [img, th1, th2, th3,th4,th5]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]), plt.yticks([])\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 17. Morphological Transformations (형태변환)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "It’s also possible to manipulate the figures of images by filtering, which is called as morphological transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Morphologicla Transformation은 이미지를 Segmentation하여 단순화, 제거, 보정을 통해서 형태를 파악하는 목적으로 사용이 됩니다.   \n",
    "일반적으로 binary나 grayscale image에 사용이 됩니다.   \n",
    "사용하는 방법으로는 Dilation(팽창), Erosion(침식), 그리고 2개를 조합한 Opening과 Closing이 있습니다.   \n",
    "여기에는 2가지 Input값이 있는데, 하나는 원본 이미지이고 또 다른 하나는 structuring element입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Erosion(침식)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Erosion is the technique for shrinking figures and it’s usually processed in a grayscale. . By applying a filter we remove any 0 values under the given area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "각 Pixel에 structuring element를 적용하여 하나라도 0이 있으면 대상 pixel을 제거하는 방법입니다. 아래 그림은 대상 이미지에 십자형 structuring element를 적용한 결과 입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_2_15.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "위 그림에서 가운데 있는 십자형 Structuring Element를 Original Image에 적용을 합니다. 원본의 각 pixel에 적용을 하여 겹치는 부분이 없는 부분이 하나라도 있으면 그 중심 pixel을 제거하는 방식입니다. 최종적으로 우측의 분홍색 영역만 남게 됩니다. 이 방법은 작은 Object를 제거하는 효과가 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/morp.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### erosion 의 예 (커널에 따른)\n",
    "<img style=\"float: left;\" src=\"pic/erosion.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Dilation(팽창)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Dilation is the opposite to erosion. It is making objects expand and the operation will be also opposite to that of erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Erosion과 반대로 대상을 확장한 후 작은 구멍을 채우는 방법입니다. Erosion과 마찬가지로 각 pixel에 structuring element를 적용합니다. 대상 pixel에 대해서 OR 연산을 수행합니다. 즉 겹치는 부분이 하나라도 있으면 이미지를 확장합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_2_16.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "위 그림은 십자형 structuring element를 원본이미지에 OR 연산을 적용합니다. 최종적으로 확장된 이미지를 얻을 수 있습니다. 결과적으로 경계가 부드러워 지고, 구멍이 메꿔지는 효과를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### dilation의 예\n",
    "<img style=\"float: left;\" src=\"pic/dilation.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "titles = ['image']\n",
    "images = [img]\n",
    "\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "titles = ['image', 'mask']\n",
    "images = [img, mask]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "mask에 있는 흰공에 있는 검음 점을 없애자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation']\n",
    "images = [img, mask, dilation]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "검은 점이 줄어 들기는 했으나 없어지지 않았다. 반복 적용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((2,2), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation']\n",
    "images = [img, mask, dilation]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "아직 조금 남아있다. kernal 크기를 조정해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation']\n",
    "images = [img, mask, dilation]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "검은 점은 없어졌다. 그런데 흰 부분이 커졌다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation', 'erosion']\n",
    "images = [img, mask, dilation, erosion]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "erosion을 하면 흰 면적이 줄어들고, 검은 점은 커진다. 5번 적용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=5)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation', 'erosion']\n",
    "images = [img, mask, dilation, erosion]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Opening and Closing\n",
    "Opening and closing operation is the mixed version of erosion and dilation. Opening performs erosion first and then dilation is performed on the result from the erosion while closing performs dilation first and the erosion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Opening과 Closing은 Erosion과 Dilation의 조합 결과 입니다. 차이는 어느 것을 먼저 적용을 하는 차이 입니다.\n",
    "\n",
    "- Opeing : Erosion적용 후 Dilation 적용. 작은 Object나 돌기 제거에 적합\n",
    "- Closing : Dilation적용 후 Erosion 적용. 전체적인 윤곽 파악에 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/opening.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/fig_2_17.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation', 'erosion', 'opening']\n",
    "images = [img, mask, dilation, erosion, opening]\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "closing = dialation 후 closing 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "titles = ['image', 'mask', 'dilation', 'erosion', 'opening', 'closing']\n",
    "images = [img, mask, dilation, erosion, opening, closing]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "mg는 dilation 과 erosion의 차이  \n",
    "th 는 원본(mask)과 opening 과의 차이\n",
    "bh 는 원본(mask)과 closing 과의 차이\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/smarties.png', cv2.IMREAD_GRAYSCALE)\n",
    "_, mask = cv2.threshold(img, 220, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "dilation = cv2.dilate(mask, kernel, iterations=2)\n",
    "erosion = cv2.erode(mask, kernel, iterations=1)\n",
    "opening = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
    "closing = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "mg = cv2.morphologyEx(mask, cv2.MORPH_GRADIENT, kernel)\n",
    "th = cv2.morphologyEx(mask, cv2.MORPH_TOPHAT, kernel)\n",
    "bh = cv2.morphologyEx(mask, cv2.MORPH_BLACKHAT, kernel)\n",
    "titles = ['image', 'mask', 'dilation', 'erosion', 'opening', 'closing', 'mg', 'th', 'bh']\n",
    "images = [img, mask, dilation, erosion, opening, closing, mg, th, bh]\n",
    "\n",
    "for i in range(9):\n",
    "    plt.subplot(2, 5, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 18. Smoothing Images or Blurring Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "이미지에 대하여, Low-pass filter(LPF)를 적용하면 노이즈제거나 blur처리를 할 수 있으며, High-pass filter(HPF)를 적용하면 경계선을 찾을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Image Blurring\n",
    "Image Blurring은 low-pass filter를 이미지에 적용하여 노이즈를 제거하거나 경계선을 흐리게 할 수 있습니다. OpenCV에는 4가지 형태의 blurring 방법을 제공하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Averaging blurring\n",
    "- Gaussian blurring: 이미지의 Gaussian Noise (전체적으로 밀도가 동일한 노이즈, 백색노이즈)를 제거하는 데 가장 효과적입니다.\n",
    "- median blurring: salt-and-pepper noise 제거에 가장 효과적입니다. \n",
    "- bilateral filtering: 지금까지의 Blur처리는 경계선까지 Blur처리가 되어, 경계선이 흐려지게 됩니다. Bilateral Filtering(양방향 필터)은 경계선을 유지하면서 Gaussian Blur처리를 해주는 방법입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Blurring (or Smoothing)\n",
    "The goal of blurring is to perform noise reduction. But we have to pay extra care here. If we apply edge detection algorithms to the images with high resolution, we’ll get too many detected outcomes that we aren’t interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "<img style=\"float: left;\" src=\"pic/bur.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "On the contrary, if we blur the images too much, we‘ll lose the data. Therefore we need to find an adequate amount of blurring we’re going to apply without losing desirable edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def nothing(x):\n",
    "    pass\n",
    "\n",
    "def bluring():\n",
    "    img = cv2.imread('pic/model.jpg')\n",
    "    \n",
    "    cv2.namedWindow('BlurPane')\n",
    "    cv2.createTrackbar('Filter_Type', 'BlurPane', 0, 3, nothing)\n",
    "    cv2.createTrackbar('Filter_Size', 'BlurPane', 0, 5, nothing)\n",
    "    \n",
    "    filter_type = cv2.getTrackbarPos('Filter_Type', 'BlurPane')\n",
    "    filter_size = cv2.getTrackbarPos('Filter_Size', 'BlurPane')\n",
    "\n",
    "    while True:\n",
    "        filter_size = filter_size * 2 + 1\n",
    "\n",
    "        if filter_type == 0:\n",
    "            blur = cv2.blur(img, (filter_size, filter_size))\n",
    "        elif filter_type == 1:\n",
    "            blur = cv2.GaussianBlur(img, (filter_size, filter_size), 0)\n",
    "        elif filter_type == 2:\n",
    "            blur = cv2.medianBlur(img, filter_size)\n",
    "        elif filter_type == 3:\n",
    "            blur = cv2.cv2.bilateralFilter(img, filter_size, 75, 75)\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "        cv2.imshow('BlurPane', blur)\n",
    "        \n",
    "        k=cv2.waitKey(1) & 0xFF\n",
    "        if k == 27:\n",
    "            break\n",
    "            \n",
    "        filter_type = cv2.getTrackbarPos('Filter_Type', 'BlurPane')\n",
    "        filter_size = cv2.getTrackbarPos('Filter_Size', 'BlurPane')\n",
    "    \n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "bluring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/opencv-logo.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "titles = ['image', '2D Convolution']\n",
    "images = [img, dst]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/opencv-logo.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "blur = cv2.blur(img, (5, 5))\n",
    "\n",
    "titles = ['image', '2D Convolution', 'blur']\n",
    "images = [img, dst, blur]\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(1, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/opencv-logo.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "blur = cv2.blur(img, (5, 5))\n",
    "gblur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "titles = ['image', '2D Convolution', 'blur', 'GaussianBlur']\n",
    "images = [img, dst, blur, gblur]\n",
    "\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "medianBlue 은 salt and pepper Noise 제거에 적합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/opencv-logo.png')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "blur = cv2.blur(img, (5, 5))\n",
    "gblur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "median = cv2.medianBlur(img, 5)\n",
    "bilateralFilter = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "titles = ['image', '2D Convolution', 'blur', 'GaussianBlur', 'median', 'bilateralFilter']\n",
    "images = [img, dst, blur, gblur, median, bilateralFilter]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread('pic/lena.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "kernel = np.ones((5, 5), np.float32)/25\n",
    "dst = cv2.filter2D(img, -1, kernel)\n",
    "blur = cv2.blur(img, (5, 5))\n",
    "gblur = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "median = cv2.medianBlur(img, 5)\n",
    "bilateralFilter = cv2.bilateralFilter(img, 9, 75, 75)\n",
    "\n",
    "titles = ['image', '2D Convolution', 'blur', 'GaussianBlur', 'median', 'bilateralFilter']\n",
    "images = [img, dst, blur, gblur, median, bilateralFilter]\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "bilateral Filter는 noise를 제거할 때 border를 sharp하게 유지시켜준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Bilateral Filtering is an advanced version of Gaussian blurring. Blurring produces not only dissolving noises but also smoothing edges. And bilateral filter can keep edges sharp while removing noises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 19. Image Gradients and Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "An image gradient is a directional change in the intensity or color in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "I believe we are already familiar with the concept of gradients. In mathematics, the gradient geometrically represents the slope of the graph of a function with multi-variables. As it is a vector-valued function, it takes a direction and a magnitude as its components. Here we can also bring the same concept to the pixel values of images as well. The image gradient represents directional changes in the intensity or color mode and we can use this concept for locating edges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "영상처리에서 gradient는 영상에서의 edge(경계) 및 그 방향을 찾는 용도로 활용 됩니다.   \n",
    "이미지 (x,y)에서의 벡터값(크기와 방향, 즉 밝기와 밝기의 변화하는 방향)을 구해서 해당 pixel이 edge에 얼마나 가까운지, 그리고 그 방향이 어디인지 쉽게 알수 있게 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Edge Detection 방법\n",
    "\n",
    "- Laplacian\n",
    "- Sobel\n",
    "- Canny "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "titles = ['image']\n",
    "images = [img ]\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "\n",
    "titles = ['image', 'Laplacian']\n",
    "images = [img, lap]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's change ksize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=5)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "\n",
    "titles = ['image', 'Laplacian ksize=5']\n",
    "images = [img, lap]\n",
    "\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's change ksize=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "\n",
    "titles = ['image', 'Laplacian ksize=3']\n",
    "images = [img, lap ]\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY']\n",
    "images = [img, lap, sobelX, sobelY]\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"sudoku.png\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY']\n",
    "images = [img, lap, sobelX, sobelY]\n",
    "for i in range(4):\n",
    "    plt.subplot(2, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/sudoku.png\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY', 'sobelCombined']\n",
    "images = [img, lap, sobelX, sobelY, sobelCombined]\n",
    "for i in range(5):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## 20. Canny Edge Detection "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The Canny edge detector is an edge detection operator that uses a multi-stage algorithm to detect a widw range of edges in images. It was developed  by John F. Canny in1986."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The Process of Canny edge detection algorithm can be broken down to 5 different steps:\n",
    "\n",
    "1. Noise reduction (Apply Gaussian filter to smooth the image in order to remove the noise)\n",
    "2. Gradient calculation(Find the intensity gradients of the image)\n",
    "3. Non-maximum suppression (to get rid of spurious response to edge detection)\n",
    "4. Double threshold (to determine potential edges)\n",
    "5. Track edge by hysteresis (Finalize the detection of edges by suppressing all the other edges that are weak and not connected to strong edges.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\",0)\n",
    "\n",
    "titles = ['image']\n",
    "images = [img]\n",
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\",0)\n",
    "canny = cv2.Canny(img, 100, 200)\n",
    "\n",
    "titles = ['image', 'canny']\n",
    "images = [img, canny]\n",
    "for i in range(2):\n",
    "    plt.subplot(1, 2, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Trackbar를 이용해서 Canny 함수의 threshold 1 및 2 값을 조정하는걸 추천."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "앞 장에서 소개한 기법들과 그 결과를 비교해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"pic/messi5.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY', 'sobelCombined', 'Canny']\n",
    "images = [img, lap, sobelX, sobelY, sobelCombined, edges]\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "img = cv2.imread(\"pic/sudoku.png\", cv2.IMREAD_GRAYSCALE)\n",
    "lap = cv2.Laplacian(img, cv2.CV_64F, ksize=3)\n",
    "lap = np.uint8(np.absolute(lap))\n",
    "sobelX = cv2.Sobel(img, cv2.CV_64F, 1, 0)\n",
    "sobelY = cv2.Sobel(img, cv2.CV_64F, 0, 1)\n",
    "edges = cv2.Canny(img,100,200)\n",
    "\n",
    "sobelX = np.uint8(np.absolute(sobelX))\n",
    "sobelY = np.uint8(np.absolute(sobelY))\n",
    "\n",
    "sobelCombined = cv2.bitwise_or(sobelX, sobelY)\n",
    "\n",
    "titles = ['image', 'Laplacian', 'sobelX', 'sobelY', 'sobelCombined', 'Canny']\n",
    "images = [img, lap, sobelX, sobelY, sobelCombined, edges]\n",
    "for i in range(6):\n",
    "    plt.subplot(2, 3, i+1), plt.imshow(images[i], 'gray')\n",
    "    plt.title(titles[i])\n",
    "    plt.xticks([]),plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    " ## 과제 2 (1점)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "pic/sudoku.png 이미지에 대하여 Canny 함수를 이용하여 edge를 detect 할 때, edge를 잘 detect 하도록, Trackbar를 이용해서 Canny 함수의 threshold 1 및 2 값을 조정하는 프로그램을 작성하고, 가장 알맞는 threshold 1 값과 threshold 2 값을 명시하여, 과제함에 제출하세요. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
